#include <warbler/lexicon/tokenizer.hpp>

// local headers
#include <warbler/util/print.hpp>

// standard headers
#include <cstring>
#include <cstdlib>
#include <stdexcept>
#include <unordered_map>

#define MAX_KeywordLENGTH	(15)

namespace warbler::lexicon
{
	using source::File;
	using lexicon::Token;

	enum class CharType
	{
		Invalid,
		Null,
		Identifier,
		Separator,
		Dot,
		Digit,
		Operator,
		Quote
	};

	static CharType char_types[256];

	


	

	static Token get_separator_token(const File& file, const usize start_pos)
	{
		TokenType type;

		switch (file[start_pos])
		{
			case '(':
				type = TokenType::LeftParenthesis;
				break;

			case ')':
				type = TokenType::RightParenthesis;
				break;

			case '[':
				type = TokenType::LeftBracket;
				break;

			case ']':
				type = TokenType::RightBracket;
				break;

			case '{':
				type = TokenType::LeftBrace;
				break;

			case '}':
				type = TokenType::RightBrace;
				break;

			case ',':
				type = TokenType::Comma;
				break;

			case ';':
				type = TokenType::Semicolon;
				break;
			
			default:
				throw std::runtime_error("invalid chracter was passed to get_separator_token: '" + String(1, file[start_pos]) + "'");
		}

		return Token(Token(file, start_pos, 1), type);
	}

	static Result<Token> get_digit_token(const File& file, const usize start_pos)
	{
		auto pos = start_pos;
		usize decimal_count = 0;

		while (true)
		{
			CharType type = get_char_type(file[pos]);

			if (type == CharType::Dot)
			{
				decimal_count += 1;
			}
			else if (type != CharType::Digit)
			{
				break;
			}

			pos += 1;
		}

		auto length = pos - start_pos;

		if (decimal_count > 1)
		{
			print_error(source::Snippet(file, start_pos, length), "only one decimal is allowed in float literal");
			return {};
		}

		auto type = decimal_count > 0
			? TokenType::FloatLiteral
			: TokenType::IntegerLiteral;

		return Token(Token(file, start_pos, length), type);
	}

	

	static Result<Token> get_next_token(const source::File& file, const usize start_pos)
	{
		auto type = get_char_type(file[start_pos]);

		switch (type)
		{
			case CharType::Null:
				break;

			case CharType::Identifier:
				return get_identifier_token(file, start_pos);

			case CharType::Separator:
				return get_separator_token(file, start_pos);

			case CharType::Dot:
				return get_dot_token(file, start_pos);

			case CharType::Digit:
				return get_digit_token(file, start_pos);

			case CharType::Operator:
				return get_operator_token(file, start_pos);

			case CharType::Quote:
				return get_quote_token(file, start_pos);

			case CharType::Invalid:
				print_error(source::Snippet(file, start_pos, 1), "invalid character in source file '" + String(1, file[start_pos]) + "'");
				throw std::exception();
		}

		return Token(Token(file, start_pos, 1), TokenType::EndOfFile);
	}

	Result<Array<Token>> tokenize(const source::File& file)
	{	
		Array<Token> out;

		out.reserve(10);

		usize position = 0;

		do
		{
			position = find_next_position(file, position);

			if (out.size() == out.capacity())
				out.reserve(out.size() * 2);

			auto res = get_next_token(file, position);

			if (!res)
				return {};

			out.emplace_back(res.unwrap());
			position += out.back().token().length();
		}
		while (out.back().type() != TokenType::EndOfFile);

		return out;
	}
}
